# Instruction-Fine-Tuned-GPT-2

Ce projet vise Ã  affiner un modÃ¨le GPT-2 "small" sur un jeu de donnÃ©es dâ€™instructions pour amÃ©liorer sa capacitÃ© Ã  gÃ©nÃ©rer des rÃ©ponses pertinentes. Lâ€™objectif est de transformer le modÃ¨le de base en un chatbot performant capable de comprendre et rÃ©pondre aux questions en langage naturel.

Nous avons suivi une approche mÃ©thodique en testant diffÃ©rentes configurations de modÃ¨le, techniques de prÃ©traitement des donnÃ©es, stratÃ©gies dâ€™entraÃ®nement et mÃ©thodes dâ€™Ã©valuation afin dâ€™optimiser les performances du modÃ¨le.

ğŸ›  1. Installation et Importation des BibliothÃ¨ques
Nous avons commencÃ© par importer les bibliothÃ¨ques essentielles telles que PyTorch, Transformers (Hugging Face), Pandas et Datasets pour le traitement des donnÃ©es et lâ€™entraÃ®nement du modÃ¨le.

ğŸ’¡ ProblÃ¨me rencontrÃ© : Initialement, nous avons tentÃ© dâ€™utiliser une autre version de GPT-2 (gpt2-medium) mais avons rencontrÃ© des problÃ¨mes de mÃ©moire GPU, nous obligeant Ã  revenir Ã  la version "small".

ğŸ— 2. ImplÃ©mentation de GPT-2 Small et Tests Initiaux
Nous avons chargÃ© le modÃ¨le GPT-2 Small et testÃ© sa gÃ©nÃ©ration de texte avec une question basique.

ğŸ” Observations :

Les rÃ©ponses Ã©taient souvent rÃ©pÃ©titives et non structurÃ©es.
Lâ€™absence dâ€™instruction claire dans les prompts affectait la pertinence des rÃ©ponses.
Le modÃ¨le ne semblait pas bien comprendre les intentions des utilisateurs.
ğŸ’¡ HypothÃ¨se : Lâ€™ajout dâ€™un dataset spÃ©cialisÃ© en instruction pourrait amÃ©liorer le comportement du modÃ¨le.

ğŸ“š 3. PrÃ©paration et Exploration du Dataset
Nous avons utilisÃ© le dataset Stanford Alpaca contenant des paires (instruction, input, output).

ğŸ“Œ Ã‰tapes suivies :
TÃ©lÃ©chargement du dataset et transformation en DataFrame.
Nettoyage des donnÃ©es (suppression des doublons et gestion des valeurs manquantes).
RÃ©duction du dataset : Pour des raisons de temps dâ€™entraÃ®nement, nous avons sÃ©lectionnÃ© seulement 10% des donnÃ©es.
Fractionnement en ensembles dâ€™entraÃ®nement (85%), validation (10%) et test (5%).
ğŸ” Premiers tests :

GÃ©nÃ©ration de rÃ©ponses plus cohÃ©rentes, mais parfois hors contexte.
Besoin dâ€™amÃ©liorer la gestion des instructions complexes.
ğŸ’¡ Solution envisagÃ©e : Introduire une mise en forme plus rigoureuse des donnÃ©es en encodant chaque entrÃ©e sous une structure claire.

ğŸ¯ 4. Fine-Tuning du ModÃ¨le GPT-2
Nous avons mis en place un entraÃ®nement supervisÃ© en utilisant les instructions formatÃ©es comme entrÃ©e du modÃ¨le.

ğŸ“Œ Optimisations implÃ©mentÃ©es :
âœ… Ajout dâ€™un token de padding pour gÃ©rer des sÃ©quences de longueurs variables.
âœ… Utilisation de batch_size rÃ©duit (1) pour Ã©viter les dÃ©passements mÃ©moire GPU.
âœ… Introduction de lâ€™AMP (Mixed Precision) pour accÃ©lÃ©rer lâ€™entraÃ®nement et Ã©conomiser de la mÃ©moire.
âœ… Application dâ€™un scheduler linÃ©aire du taux dâ€™apprentissage pour optimiser la convergence.
âœ… ImplÃ©mentation du Gradient Accumulation pour stabiliser lâ€™apprentissage.

ğŸ“Š 5. Ã‰valuation du ModÃ¨le et AmÃ©liorations
AprÃ¨s lâ€™entraÃ®nement, nous avons Ã©valuÃ© le modÃ¨le avec plusieurs mÃ©triques :

PerplexitÃ© (PPL) : Permet de mesurer la qualitÃ© du modÃ¨le sur le texte gÃ©nÃ©rÃ©.
â¡ï¸ RÃ©sultat final : 3.37 (correct mais amÃ©liorable).

Accuracy Token-Level : Mesure le taux de prÃ©diction correcte des tokens.
â¡ï¸ RÃ©sultat : Erreur due Ã  une mauvaise gestion des labels (-100 pour le padding), corrigÃ©e ensuite.

BLEU Score : Pour mesurer la similaritÃ© entre le texte gÃ©nÃ©rÃ© et la rÃ©ponse attendue.
â¡ï¸ Erreur dâ€™importation de load_metric, nÃ©cessitant une mise Ã  jour de la librairie datasets.

ğŸ” ProblÃ¨mes identifiÃ©s et solutions :

ProblÃ¨me : GÃ©nÃ©ration encore trop gÃ©nÃ©rique.
â¡ï¸ Solution : Ajuster les hyperparamÃ¨tres et expÃ©rimenter avec diffÃ©rentes stratÃ©gies dâ€™augmentation de donnÃ©es.
ProblÃ¨me : Manque de diversitÃ© dans les rÃ©ponses.
â¡ï¸ Solution : Ajouter un mÃ©canisme de pÃ©nalisation des rÃ©pÃ©titions (Top-k Sampling).
ğŸ“ 6. Tests et RÃ©sultats
Nous avons testÃ© le modÃ¨le sur diffÃ©rentes requÃªtes :

Exemple de question :

"What are the benefits of meditation?"

ğŸ” RÃ©ponse gÃ©nÃ©rÃ©e :
"Meditation helps relax the mind and body, reduces stress, and improves circulation. It is also beneficial for mental clarity and emotional stability."

â¡ï¸ ComparÃ© Ã  la version initiale de GPT-2, la rÃ©ponse est plus prÃ©cise et mieux structurÃ©e.

ğŸ”¥ Prochaines amÃ©liorations :

IntÃ©grer un meilleur mÃ©canisme de contrÃ´le de la longueur des rÃ©ponses.
Tester un fine-tuning plus long avec plus de donnÃ©es.
Explorer dâ€™autres architectures comme GPT-3 ou LLaMA pour amÃ©liorer la qualitÃ© des rÃ©ponses.
